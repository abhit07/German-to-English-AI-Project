{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"german.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi.', 'Hallo!'],\n",
       "       ['Hi.', 'Grüß Gott!'],\n",
       "       ['Run!', 'Lauf!'],\n",
       "       ...,\n",
       "       ['Tom held on to the rope.', 'Tom hielt sich am Seil fest.'],\n",
       "       ['Tom hid behind the door.',\n",
       "        'Tom versteckte sich hinter der Tür.'],\n",
       "       ['Tom hid under the table.', 'Tom versteckte sic']], dtype='<U83')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi', 'Hallo'],\n",
       "       ['Hi', 'Grüß Gott'],\n",
       "       ['Run', 'Lauf'],\n",
       "       ...,\n",
       "       ['Tom held on to the rope', 'Tom hielt sich am Seil fest'],\n",
       "       ['Tom hid behind the door', 'Tom versteckte sich hinter der Tür'],\n",
       "       ['Tom hid under the table', 'Tom versteckte sic']], dtype='<U83')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hi', 'hallo'],\n",
       "       ['hi', 'grüß gott'],\n",
       "       ['run', 'lauf'],\n",
       "       ...,\n",
       "       ['tom held on to the rope', 'tom hielt sich am seil fest'],\n",
       "       ['tom hid behind the door', 'tom versteckte sich hinter der tür'],\n",
       "       ['tom hid under the table', 'tom versteckte sic']], dtype='<U83')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZTElEQVR4nO3dfbSlZXnf8e8vjC+IGiToqEAdTdBExRdAQ+qqmUiNVKyYVBtTNZDQmmQpYkuWQvKHWV1lrUmaMSpWG0QdNBNeRBTqC5Gg0zSrAgJixglSUSYwiCJVFLRRBq/+se/N7Dmz55x9Xp/z7PP9rDXrnHPvZ599nX2eM9fzct/XlapCkqSf6joASdLqYEKQJAEmBElSY0KQJAEmBElSY0KQJAEmBEk9lGRLkv/SdRzTxoQgSQJMCJKkxoTQQ0memOSjSb6d5NYkb2rjf5zk4iQfSnJvkh1Jjh153tFJvtge+0iSizztVh8keW6SG9q+exHw8JHHXpbkxiT3JPnfSZ418lgl+bmRr73UNAsTQs8k+SngfwBfAg4DjgfenOQlbZOXAxcCBwOXA+9uz3so8DFgC3AIcAHwaysYurQgbd/9OPBhBvvuR4B/0x47GvgA8LvAzwB/AVye5GGdBNtzJoT+eR7w2Kr6z1X146r6OvA+4NXt8b+rqk9V1QMM/oCe3caPA9YB76qq+6vqUuDalQ5eWoDjgIcA72j77iXAF9pj/wH4i6q6pqoeqKrzgR+152ie1nUdgObtScATk9wzMnYA8L+AfwS+OTL+Q+DhSdYBTwTuqL2rGd6+zLFKS2HcvvuP7eOTgJOTnDby2EPbczRPniH0z+3ArVV18Mi/R1XVS+d43p3AYUkyMnbE8oUpLZlx++4/ax9vB86e8ffwiKq6oD3+Q+ARI897/ArE21smhP65Fvh+krcmOTDJAUmemeR5czzv88ADwBuTrEtyEvD8ZY9WWrzPA7uBN7V999fZs+++D/i9JL+YgYOSnJjkUe3xG4F/1/5OTgB+ecWj7xETQs+0ewP/GngOcCtwN3Ae8NNzPO/HwK8DpwL3AK8FPsHgequ0ao3su6cA3wV+A7i0PXYdg/sI726P3dK2Gzqdwd/LPcBrGNyc1n7EBjlrV5JrgP9eVR/sOhZJ3fMMYQ1J8stJHt9Ou08GngVc0XVcklYHZxmtLU8DLgYeCXwNeGVV3dltSJJWCy8ZSZIALxlJkpreXjI69NBDa8OGDSv6mj/4wQ846KCDVvQ1F8N453b99dffXVWPXdEXXaAu9vn56MP+1ocYYXnjnHWfr6pe/jvmmGNqpX3uc59b8ddcDOOdG3Bdjdm/GNTHuQv48ozx04CbgR3An46Mn8VgyuPNwEtGxo8BtrfH3sWey7QPAy5q49cAG8bFUR3v8/PRh/2tDzFWLW+c+9vnq8pLRtJ+bAFOGB1I8ivAScCzquoZwJ+18aczqCX1jPac9yQ5oD3tvcDrgSPbv+H3PBX4blX9HPDnwJ8s5w8jTcKEII1RVX8LfGfG8O8Dm6rqR22bu9r4ScCFVfWjqrqVwVH/85M8AXh0VX2+HZl9CHjFyHPOb59fAhw/ozSDtOJ6ew9B6sBTgX+R5Gzgn4A/qKovMChDfvXIdrva2P3t85njtI+3A1TV7iTfY1C++e7RF0zyegZnGKxfv55t27Yt8Y+0dO67775VHR/0I0boLk4TgjS5dcBjGJRWfh5wcZKnAOOO7GuWceZ4bM9A1bnAuQDHHntsbdy4cf5Rr5Bt27axmuODfsQI3cXpJSNpcruAS9u9uWuBnwCHtvHRyrGHA99o44ePGWf0Oa08+U+z7yUqaUWZEKTJfRx4EUCSpzKou383g850r07ysCRPZnDz+NoarAK/N8lx7f7AbwGXte91OXBy+/yVwGfbfQapM14yksZIcgGwETg0yS7gbQymon4gyZeBHwMnt//EdyS5GPgHBmWa31CDqrQwuBG9BTgQ+HT7B/B+4MNJbmFwZjDseCd1xoQgjVFVv7mfh167n+3PBs4eM34d8Mwx4/8EvGoxMUpLzUtGkiTAM4Sptv2O73HKmZ988Oudm07sMBr10YaR/Qfch6adZwiSJMCEIElqTAiSJMCEIElqTAiSJMCEIElqTAiSJMCEIElq5kwIST6Q5K5Wv2V0/LQkNyfZkeRPR8bPSnJLe+wlI+PHJNneHnvXsBlIKwh2URu/JsmGJfz5JEkTmuQMYQu2EpSkqTdnQrCVoCStDQu9hzBsJXhNkv+Z5Hlt/MG2gM2wZeBhTNhKEBi2EpQkraCFFrdb8VaC0H1/2b70Yx1afyCccdTuB79e7bH37f2Vps1CE8KDrQSBa5MsRSvBXXO1Euy6v2xf+rEOnbP1MjZv3/Mr3vmajd0FM4G+vb/StFnoJaOPYytBSZoqk0w7vQD4PPC0JLuSnMqgleBT2lTUC2mtBKtqBzBsJXgF+7YSPI/BjeavsXcrwZ9prQT/E3Dmkv100gLtb7p1e+wPklSSQ0fGnG6t3pvzkpGtBLVGbQHezWBG3IOSHAG8GLhtZGx0uvUTgb9J8tR2MDScbn018CkG060/zch06ySvZjDd+jeW+WeSZuVKZWmM/Uy3hsFambew98QHp1trKthCU5pQkpcDd1TVl2b8330YgzOAoeG06vuZcLp1kuF067tnvGanM+tGZ6nB7DPV+jBLrA8xQndxmhCkCSR5BPBHwK+Oe3jM2JJMt+56Zt0pM3sqzzJTrQ+zxPoQI3QXp5eMpMn8LPBk4EtJdjKYOn1DksezuOnWzDXdWlopJgRpAlW1vaoeV1UbqmoDg//Qj66qb+J0a00JE4I0xn6mW4/ldGtNC+8hSGPMMt16+PiGGV873Vq95xmCJAkwIUiSGhOCJAkwIUiSGhOCJAkwIUiSGhOCJAkwIUiSGhOCJAmYrGOanaMkaQ2Y5AxhC4MuT3uZoHPUCcB7khzQHh52jjqy/Rt+zwc7RzFoPvInC/lBJEmLM2dCsHOUJK0NCypu10XnqPa6nXaP6ku3paH1B+7d8Wq1x96391eaNvNOCF11joLuu0f1pdvS0DlbL2Pz9j2/4tm6Xa0GfXt/pWmzkFlGdo6SpCk074Rg5yhJmk6TTDu1c5QkrQFz3kOwc5QkrQ2uVJbGGLcgM8l/TfKVJH+f5GNJDh55zAWZ6j0TgjTeFvZdkHkl8Myqehbwf4CzwAWZmh4mBGmMcQsyq+ozVTVc2HE1e2bOuSBTU2FBC9Mk8TvARe3zZVuQ2fVizNGFjTD74sY+LCzsQ4zQXZwmBGmekvwRsBvYOhwas9mSLMjsejHmKWd+cq+vZ1vc2IeFhX2IEbqL00tG0jwkORl4GfCakfUyLsjUVDAhSBNKcgLwVuDlVfXDkYdckKmp4CUjaYy2IHMjcGiSXcDbGMwqehhwZbv/e3VV/V5V7UgyXJC5m30XZG4BDmSwGHN0QeaH24LM7zCYpSR1yoQgjbGfBZnvn2V7F2Sq97xkJEkCTAiSFmnDmZ9kw5mfZPsd32PDjFlJ6hcTgiQJMCFIkhoTgiQJMCFIkppJGuRYBliS1oBJzhC2YBlgSZp6cyYEywBL0tqwFCuVV6QMMHRfCrgvpXOH1h+4d/ni1R57395fadosKiGsZBlg6L4UcF9K5w6ds/UyNm/f8yuerXTxatC391eaNgueZWQZYEmaLgtKCJYBlqTpM+clI8sAS9LaMGdCsAywJK0NrlSWJAEmBElSY0KQJAEmBGms/dTwOiTJlUm+2j4+ZuQxa3ip90wI0nhb2LeG15nAVVV1JHBV+9oaXpoaJgRpjHE1vNi77tb57F2Pyxpe6r2lqGWkNWZm39ydm07sKJIVt74tsqSq7kzyuDa+bDW8uq7fNVoLC8bXwxpuM6ydtZrrUfWlXlZXcZoQpMVbthpeXdfvOmVm8h9TD2u4zRlH7Wbz9nWrumZWX+pldRWnl4ykyX2rXQaifbyrjVvDS1PBhCBNbrTu1snsXY/LGl7qPS8ZSWPsp4bXJuDiJKcCt9FKrljDS9PChCCNsZ8aXgDH72d7a3ip97xkJEkCTAiSpMaEIEkCJkgI1nSRpLVhkjOELVjTRZKm3pwJwZoukrQ2LHTa6YrXdIHu67r0pQ7K0LC2zNBSxT5JfZuF6Nv7K02bpV6HsGw1XaD7ui59qYMydM7Wy9i8fc+veKlqzExS32Yh+vb+StNmobOMrOkiSVNmoQnBmi6SNGXmvGRkTRdJWhvmTAjWdJGktcGVypIkwIQgSWpMCJIkwIQgSWpMCJIkwIQgSWpMCNI8JPmPSXYk+XKSC5I8fCnLwUtdMiFIE0pyGPAm4NiqeiZwAIOFlEtZDl7qzFIXt9MCbJhZLG7TiR1FogmsAw5Mcj/wCAY1uc5isJofBqXctwFvZaQcPHBrW43//CQ7aeXgAZIMy8F/GqlDJgRpQlV1R5I/Y1Cu5f8Bn6mqzyRZynLwe+m65Pskpc6H2wzLra/mEuZ9KbHeVZwmBGlC7d7AScCTgXuAjyR57WxPGTM2Vzn4vQc7Lvk+Sanz4TZnHLWbzdvXLVk59OXQlxLrXcXpPQRpcv8SuLWqvl1V9wOXAv+cpS0HL3XGhCBN7jbguCSPaLOCjgduYmnLwUud8ZKRNKGquibJJcANDMq7f5HB5ZxHsnTl4KXOmBCkeaiqtzHoCTLqRyxROfiVNHN2GzjDba3zkpEkCVhkQnDVpiRNjwUnBFdtStJ0Wewlo+GqzXXsWbV5EoPVmrSPr2ifP7hqs6puBYarNp9AW7VZVQV8aOQ5kqQVsuCbymtx1eZyrR6cZDXoQgxXji71912uePuyilSaVgtOCGtx1eZyrR6cZDXoQpyz9TI2b9/zK16q77tc8fZlFak0rRZzychVm5I0RRaTEFy1KUlTZDH3EFy1KUlTZFErladp1aYkrXWuVJYkASYESVJjQpAkASYESVJjQpAkASYESVJjQpAkASYEad6SHJzkkiRfSXJTkl+yD4imgQlBmr93AldU1c8Dz2ZQssU+IOo9E4I0D0keDbwQeD9AVf24qu7BPiCaAiYEaX6eAnwb+GCSLyY5L8lBwF59QIDRPiC3jzx/2O/jMCbsAyKtlEXVMpLWoHXA0cBprcDjO2mXh/ZjUX1AlrMp1MxGR7Bvs6NJmiENtxk2ZFrNTY760oSpqzhNCNL87AJ2VdU17etLGCSEbyV5QusSuGR9QJazKdTMRkewb7OjSZohDbc546jdbN6+bskaJi2HvjRh6ipOLxlJ81BV3wRuT/K0NnQ8g5Lu9gFR73mGIM3facDWJA8Fvg78NoODK/uAqNcWlRCSHAycx6CXQQG/A9wMXARsAHYC/7aqvtu2Pws4FXgAeFNV/XUbP4Y9fxifAk5vMy+kVaeqbgSOHfOQfUDUa4u9ZOR8bEmaEgtOCM7HlqTpsphLRqPzsZ8NXA+czoz52ElG52NfPfL84bzr+5lwPvZyTsGbxHJNBZtkat9CDKcBLvX3Xa54+zIlUJpWi0kIKzofG5Z3Ct4klmsq2CRT+xbinK2XsXn7nl/xUn3f5Yq3L1MCpWm1mHsI4+ZjH02bjw2wlPOxJUnLa8EJwfnYkjRdFrsOwfnYkjQlFpUQnI8tSdPD0hWSJMCEIElqTAiSJMCEIElqTAiSJMCEIElqTAiSJMCEIElqTAiSJMCEIElq7KkszVPr9HcdcEdVvSzJIdg2dlYbZpZM33RiR5FoNp4hSPN3OoN2sUO2jdVUMCFI85DkcOBE4LyRYdvGaip4yUian3cAbwEeNTLWy7axM1uhwr7tUCdplzrcZtiydbZtZvs+K6EvbVq7itOEIE0oycuAu6rq+iQbJ3nKmLFV0zZ2ZitU2Lcd6iTtUofbnHHUbjZvXzfrNrN9n5XQlzatXcW56EtGSQ5I8sUkn2hfH5LkyiRfbR8fM7LtWUluSXJzkpeMjB+TZHt77F2tc5q02rwAeHmSncCFwIuS/CW2jdWUWIp7CN5g05pQVWdV1eFVtYHBvvzZqnotto3VlFhUQvAGmwTAJuDFSb4KvLh9TVXtAIZtY69g37ax5zH4O/gato3VKrDYewjvYEpusE1iuW70LNcNt+FNvqX+vssVb19u+AFU1TZgW/v8/2LbWE2BBSeEabvBNonlutGzXDfcztl6GZu37/kVL9X3Xa54+3LDT5pWizlDGN5geynwcODRozfY2tmBN9gkqScWfA/BG2ySNF2WYx3CJuDiJKcCtwGvgsENtiTDG2y72fcG2xYGdV0+jTfYJGnFLUlC8AabJPWftYwkSYAJQZLUmBAkSYAJQZLUmBAkSYAJQZLUmBAkSYAJQZLUmBAkSYAJQZLUmBAkScDyFLebWtvv+N5evQB2bjqxw2gkaWl5hiBJAkwI0rwkOSLJ55LclGRHktPb+CFJrkzy1fbxMSPPOSvJLUluTvKSkfFjkmxvj72r9QOROmNCkOZnN3BGVf0CcBzwhiRPB84ErqqqI4Gr2te0x14NPAM4AXhPkgPa93ovgx7hR7Z/J6zkDyLNtOCE4JGS1qKqurOqbmif3wvcBBwGnASc3zY7H3hF+/wk4MKq+lFV3QrcAjy/tZd9dFV9vqoK+NDIc6ROLOam8vBI6YYkjwKuT3IlcAqDI6VNSc5kcKT01hlHSk8E/ibJU1vXtOGR0tXApxgcKdk1Tatakg3Ac4FrgPWtHSytn/jj2maHMdivh3a1sfvb5zPHZ77G6xn8bbB+/Xq2bdu2ZPGfcdTufcZmfv+Z24x7/eE26w8cfD7bNrN9n5Vw3333dfba89FVnAtOCG3nH/4B3Jtk9EhpY9vsfAad1N7KyJEScGuS4ZHSTtqREkCS4ZGSCUGrVpJHAh8F3lxV35/lpHbcAzXL+N4DVecC5wIce+yxtXHjxgXFO87ojLmhna/ZOOs2Mx8f3eaMo3azefu6WbeZ7fushG3btrGU7+Fy6SrOJbmHMNuREjB6pHT7yNOGR0SHMcGRkrRaJHkIg2SwtaoubcPfapeBaB/vauO7gCNGnn448I02fviYcakzi16HsFJHSu21lu30eRLDU+KhpXr95Tqd7lu8fTidb/e33g/cVFVvH3nocuBkYFP7eNnI+F8leTuDS6VHAtdW1QNJ7k1yHIMDqd8CzlmhH0Maa1EJYbYjpXYddUmPlJbz9HkS52y9jM3b97xlS3Xau1yn032Ltyen8y8AXgdsT3JjG/tDBong4iSnArcBrwKoqh1JLgb+gcF9tze0+2YAvw9sAQ5kcInUy6Tq1IITgkdKWmp9WAleVX/H+LNagOP385yzgbPHjF8HPHPpopMWZzFnCB4pSdIUWcwsI4+UJGmKuFJZkgSYECRJjQlBkgTYD0GaShvGrUJehbO2hvoW77TyDEGSBJgQJEmNCUGSBJgQJEmNCUGSBJgQJEmNCUGSBJgQJEmNCUGSBJgQJEmNCUGSBFjLSFJPWO9o+a2aM4QkJyS5OcktSc7sOh5pJbjfazVZFQkhyQHAfwP+FfB04DeTPL3bqKTl5X6v1Wa1XDJ6PnBLVX0dIMmFwEkM+i/P28xTS08r15Ye/f6XbL8fdzllLZrrfTjjqN1sXJlQeilV1XUMJHklcEJV/fv29euAX6yqN87Y7vXA69uXTwNuXtFA4VDg7hV+zcUw3rk9qaoeu8KvCUy236+CfX4++rC/9SFGWN4497vPr5YzhIwZ2ydTVdW5wLnLH854Sa6rqmO7ev35Mt5Vb879vut9fj768PvrQ4zQXZyr4h4CsAs4YuTrw4FvdBSLtFLc77WqrJaE8AXgyCRPTvJQ4NXA5R3HJC0393utKqviklFV7U7yRuCvgQOAD1TVjo7DGqcXp+4jjHcV69F+P6k+/P76ECN0FOequKksSerearlkJEnqmAlBkgSYEOaU5Igkn0tyU5IdSU7vOqZJJDkgyReTfKLrWCaR5OAklyT5Snuvf6nrmDS5JDuTbE9yY5Lruo4HIMkHktyV5MsjY4ckuTLJV9vHx6zCGP84yR3tvbwxyUtXKh4Twtx2A2dU1S8AxwFv6El5gdOBm7oOYh7eCVxRVT8PPJt+xa6BX6mq56yief5bgBNmjJ0JXFVVRwJXta+7tIV9YwT48/ZePqeqPrVSwZgQ5lBVd1bVDe3zexn8R3VYt1HNLsnhwInAeV3HMokkjwZeCLwfoKp+XFX3dBqUeq+q/hb4zozhk4Dz2+fnA69YyZhm2k+MnTEhzEOSDcBzgWs6DmUu7wDeAvyk4zgm9RTg28AH22Wu85Ic1HVQmpcCPpPk+lZuY7VaX1V3wuBgD3hcx/HszxuT/H27pLRil7VMCBNK8kjgo8Cbq+r7XcezP0leBtxVVdd3Hcs8rAOOBt5bVc8FfkD3p/KanxdU1dEMKre+IckLuw6ox94L/CzwHOBOYPNKvbAJYQJJHsIgGWytqku7jmcOLwBenmQncCHwoiR/2W1Ic9oF7Kqq4ZnXJQwShHqiqr7RPt4FfIxBJdfV6FtJngDQPt7VcTz7qKpvVdUDVfUT4H2s4HtpQphDkjC4tn1TVb2963jmUlVnVdXhVbWBQSmEz1bVazsOa1ZV9U3g9iRPa0PHs8DS51p5SQ5K8qjh58CvAl+e/VmduRw4uX1+MnBZh7GMNUxYza+xgu/lqihdscq9AHgdsD3JjW3sD1fyzv8acRqwtdX0+Trw2x3Ho8mtBz42OHZiHfBXVXVFtyFBkguAjcChSXYBbwM2ARcnORW4DXhVdxHuN8aNSZ7D4L7MTuB3VyweS1dIksBLRpKkxoQgSQJMCJKkxoQgSQJMCJKkxoQgSQJMCJKk5v8DpY+26KUnuUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "      deu_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6069\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Vocabulary Size: 10385\n"
     ]
    }
   ],
   "source": [
    "# prepare german tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('German Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences=True))\n",
    "      model.add(Dense(out_vocab, activation='softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "52/52 [==============================] - 155s 2s/step - loss: 4.7316 - val_loss: 3.1245\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.12454, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "52/52 [==============================] - 120s 2s/step - loss: 3.1127 - val_loss: 3.0542\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.12454 to 3.05417, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "52/52 [==============================] - 119s 2s/step - loss: 2.9893 - val_loss: 2.9736\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.05417 to 2.97362, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "52/52 [==============================] - 118s 2s/step - loss: 2.8459 - val_loss: 2.8030\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.97362 to 2.80300, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "52/52 [==============================] - 123s 2s/step - loss: 2.6814 - val_loss: 2.7020\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.80300 to 2.70202, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "52/52 [==============================] - 140s 3s/step - loss: 2.5467 - val_loss: 2.6075\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.70202 to 2.60751, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "52/52 [==============================] - 155s 3s/step - loss: 2.4276 - val_loss: 2.5374\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.60751 to 2.53738, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "52/52 [==============================] - 147s 3s/step - loss: 2.3141 - val_loss: 2.4713\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.53738 to 2.47130, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "52/52 [==============================] - 169s 3s/step - loss: 2.2010 - val_loss: 2.3645\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.47130 to 2.36447, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "52/52 [==============================] - 157s 3s/step - loss: 2.0971 - val_loss: 2.2961\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.36447 to 2.29608, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "52/52 [==============================] - 151s 3s/step - loss: 1.9969 - val_loss: 2.2729\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.29608 to 2.27289, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "52/52 [==============================] - 146s 3s/step - loss: 1.9061 - val_loss: 2.1787\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.27289 to 2.17874, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "52/52 [==============================] - 155s 3s/step - loss: 1.7968 - val_loss: 2.1417\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.17874 to 2.14169, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "52/52 [==============================] - 129s 2s/step - loss: 1.7166 - val_loss: 2.0670\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.14169 to 2.06702, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "52/52 [==============================] - 142s 3s/step - loss: 1.6199 - val_loss: 2.0494\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.06702 to 2.04945, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "52/52 [==============================] - 130s 3s/step - loss: 1.5260 - val_loss: 1.9836\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.04945 to 1.98364, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "52/52 [==============================] - 168s 3s/step - loss: 1.4443 - val_loss: 1.9407\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.98364 to 1.94074, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "52/52 [==============================] - 149s 3s/step - loss: 1.3701 - val_loss: 1.9013\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.94074 to 1.90125, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "52/52 [==============================] - 151s 3s/step - loss: 1.2882 - val_loss: 1.8554\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.90125 to 1.85541, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "52/52 [==============================] - 158s 3s/step - loss: 1.2096 - val_loss: 1.8306\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.85541 to 1.83056, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "52/52 [==============================] - 167s 3s/step - loss: 1.1432 - val_loss: 1.8091\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.83056 to 1.80906, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "52/52 [==============================] - 161s 3s/step - loss: 1.0664 - val_loss: 1.7713\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.80906 to 1.77131, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "52/52 [==============================] - 157s 3s/step - loss: 0.9974 - val_loss: 1.7621\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.77131 to 1.76212, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "52/52 [==============================] - 159s 3s/step - loss: 0.9365 - val_loss: 1.7303\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.76212 to 1.73032, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "52/52 [==============================] - 159s 3s/step - loss: 0.8670 - val_loss: 1.7189\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.73032 to 1.71887, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "52/52 [==============================] - 167s 3s/step - loss: 0.8151 - val_loss: 1.7125\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.71887 to 1.71252, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "52/52 [==============================] - 147s 3s/step - loss: 0.7655 - val_loss: 1.6781\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.71252 to 1.67810, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "52/52 [==============================] - 174s 3s/step - loss: 0.7086 - val_loss: 1.6870\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.67810\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 175s 3s/step - loss: 0.6574 - val_loss: 1.6550\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.67810 to 1.65497, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "52/52 [==============================] - 869s 17s/step - loss: 0.6074 - val_loss: 1.6514\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.65497 to 1.65138, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'model'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], eng_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>she turned on the light</td>\n",
       "      <td>she on the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>i dont hear anything</td>\n",
       "      <td>i dont hear anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>what are you afraid of</td>\n",
       "      <td>what are you afraid of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>i like to play tennis</td>\n",
       "      <td>i like playing tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7244</th>\n",
       "      <td>i want to talk to him</td>\n",
       "      <td>i want to talk to talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>she got up late</td>\n",
       "      <td>she is late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>where is my luggage</td>\n",
       "      <td>wheres is my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>we are his sons</td>\n",
       "      <td>were left is red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>youre not my type</td>\n",
       "      <td>youre not my type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>i am trying to help him</td>\n",
       "      <td>i trying to help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>do come and visit us</td>\n",
       "      <td>come and  for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>allow me to go with you</td>\n",
       "      <td>let me go with you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>he just got home</td>\n",
       "      <td>he is come to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>this is my office</td>\n",
       "      <td>its is my office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924</th>\n",
       "      <td>you cant leave me</td>\n",
       "      <td>you cant scare me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       actual                  predicted\n",
       "1047  she turned on the light            she on the     \n",
       "3257     i dont hear anything   i dont hear anything    \n",
       "5707   what are you afraid of  what are you afraid of   \n",
       "2773    i like to play tennis  i like playing tennis    \n",
       "7244    i want to talk to him   i want to talk to talk  \n",
       "2826          she got up late           she is late     \n",
       "7606      where is my luggage          wheres is my     \n",
       "7453          we are his sons       were left is red    \n",
       "3514        youre not my type      youre not my type    \n",
       "3801  i am trying to help him       i trying to help    \n",
       "4354     do come and visit us          come and  for    \n",
       "7273  allow me to go with you      let me go with you   \n",
       "3889         he just got home          he is come to    \n",
       "5508        this is my office       its is my office    \n",
       "6924        you cant leave me      you cant scare me    "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
